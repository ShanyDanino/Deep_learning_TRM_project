{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXfBUJPN686k"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpMLYbNrNAyV"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "token = userdata.get('GITHUB_TOKEN')\n",
        "\n",
        "username = \"\"\n",
        "repo_name = \"Deep_learning_TRM_project\"\n",
        "\n",
        "repo_url = f\"https://{token}@github.com/{username}/{repo_name}.git\"\n",
        "\n",
        "if not os.path.exists(\"my_repo\"):\n",
        "    !git clone {repo_url} my_repo\n",
        "else:\n",
        "    print(\"Repository already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA_2O6tiRKSq"
      },
      "outputs": [],
      "source": [
        "# Set your API key in the environment\n",
        "# Get your key from: https://wandb.ai/authorize\n",
        "os.environ[\"WANDB_API_KEY\"] = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "# Install to system (Force version compatibility)\n",
        "!uv pip install --system -e /content/my_repo/tiny_recursive_models\n",
        "!uv pip install --system torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Set the path so your custom 'our.py' is found\n",
        "os.environ[\"PYTHONPATH\"] = \"/content/my_repo/tiny_recursive_models/src\"\n",
        "sys.path.append(\"/content/my_repo/tiny_recursive_models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMJrI4cNwDpj"
      },
      "outputs": [],
      "source": [
        "# Pulling dataset files\n",
        "GITHUB_DATASET_REPO_URL = \"https://github.com/josebambu/NonoDataset.git\"\n",
        "dataset_repo_name = GITHUB_DATASET_REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
        "\n",
        "if not os.path.exists(dataset_repo_name):\n",
        "    print(f\"Cloning {dataset_repo_name}...\")\n",
        "    !git clone $GITHUB_DATASET_REPO_URL\n",
        "else:\n",
        "    print(f\"Repository '{dataset_repo_name}' already exists. Skipping clone.\")\n",
        "\n",
        "# arrange dataset\n",
        "sys.path.append(\"/content/my_repo/tiny_recursive_models/scripts/\")\n",
        "from download_dataset import rearrange_dataset\n",
        "rearrange_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76V8XDzGZXp2"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "size = 5\n",
        "epochs = 2000\n",
        "sub_train = 50000\n",
        "sub_test = 10000\n",
        "batch_size = 512\n",
        "learning_rate = 1e-4\n",
        "eval_int = 10\n",
        "dataset_path = \"../../uniform_dataset\"\n",
        "processed_dataset_path = \"data/nonogram_dataset\"\n",
        "\n",
        "RUN_NAME=\"Run_$(date +%Y%m%d_%H%M%S)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS1iHyrEWerI"
      },
      "outputs": [],
      "source": [
        "%cd /content/my_repo/tiny_recursive_models/\n",
        "!chmod +x speedrun.sh\n",
        "\n",
        "!./speedrun.sh \"build\" {size} {sub_train} {sub_test} {epochs} {batch_size} \\\n",
        "                       {learning_rate} {eval_int} {dataset_path} {processed_dataset_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_kfWgLcLrw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58403ec-33ce-40a7-f2de-b0193d3716f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access 'speedrun.sh': No such file or directory\n",
            "/bin/bash: line 1: ./speedrun.sh: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!chmod +x speedrun.sh\n",
        "\n",
        "!./speedrun.sh \"train\" {size} {sub_train} {sub_test} {epochs} {batch_size} \\\n",
        "               {learning_rate} {eval_int} {dataset_path} {processed_dataset_path} \\\n",
        "               +checkpoint_path=\"/content/drive/MyDrive/Deep_learning_project/checkpoints/$RUN_NAME\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
